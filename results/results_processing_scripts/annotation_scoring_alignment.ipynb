{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b5a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b87464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#human annotation strict consistency\n",
    "path_strict_consistency_human_annotation = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/human_annotation/strict_consistency/'\n",
    "path_soft_consistency_human_annotation = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/human_annotation/soft_consistency/'\n",
    "\n",
    "#strict consistency\n",
    "path_no_context_strict_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/ChatGPT/strict_consistency/'\n",
    "path_no_context_strict_consistency_googlebard = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleBard/strict_consistency/'\n",
    "path_context_strict_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/ChatGPT/strict_consistency/'\n",
    "\n",
    "#soft consistency\n",
    "path_no_context_soft_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/ChatGPT/soft_consistency/'\n",
    "path_no_context_soft_consistency_googlebard = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleBard/soft_consistency/'\n",
    "path_context_soft_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/ChatGPT/soft_consistency/'\n",
    "\n",
    "#datasets names list\n",
    "dataset_names_list = [\"Education_expenditure_and_indicators.csv\",\n",
    "                      \"Health_expectancy.csv\",\n",
    "                      \"Listed_monuments.csv\", \n",
    "                      \"Livestock.csv\",\n",
    "                      \"Milk_supply_and_dairy_production.csv\",\n",
    "                      \"Mobility.csv\",\n",
    "                      \"Plant_protection_products.csv\",\n",
    "                      \"Population_dynamics.csv\",\n",
    "                      \"Social_security.csv\",\n",
    "                      \"Trade_and_industry.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad00b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df_for_alignment_calculation(human_annotation_path, machine_annotation_path):\n",
    "    \n",
    "    h_df = pd.read_csv(human_annotation_path).set_index('col_headers').T\n",
    "    m_df = pd.read_csv(machine_annotation_path)\n",
    "    m_df.drop(columns=['run_index'], inplace=True) if 'run_index' in m_df.columns else None\n",
    "    m_df.drop(columns=['ID'], inplace=True) if 'ID' in m_df.columns else None\n",
    "    \n",
    "    return h_df, m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3477afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alignment_score(h_df, m_df):\n",
    "    \n",
    "    comparison_results = {}\n",
    "\n",
    "    human_annotators_count = 3\n",
    "    llm_runs_count = 10\n",
    "\n",
    "    for column in h_df.columns:\n",
    "        h_df[column] = pd.to_numeric(h_df[column], errors='coerce')\n",
    "        h_counts = h_df[column].value_counts()\n",
    "\n",
    "        comparison_results[column] = {}\n",
    "\n",
    "        for value, count in h_counts.items():\n",
    "            m_count = m_df[m_df[column] == value].shape[0]\n",
    "\n",
    "            comparison_results[column][value] = {'h_df_count': Fraction(count, human_annotators_count),\n",
    "                                                 'm_df_count': Fraction(m_count, llm_runs_count)}\n",
    "\n",
    "    sum_result = Fraction(0)\n",
    "    for col, code_results in comparison_results.items():\n",
    "        for code, result in code_results.items():\n",
    "            sum_result += result['h_df_count'] * result['m_df_count']\n",
    "\n",
    "    alignment_score = Fraction(sum_result, len(comparison_results))\n",
    "    \n",
    "    return alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6844312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_alignment_code(human_annotation_folder_path, \n",
    "                                     machine_annotation_folder_path, \n",
    "                                     dataset_name, \n",
    "                                     alignment_score_df):\n",
    "    \n",
    "    human_annotation_dataset_path = os.path.join(human_annotation_folder_path, dataset_name)\n",
    "    machine_annotation_dataset_path = os.path.join(machine_annotation_folder_path, dataset_name)\n",
    "    \n",
    "    h_df, m_df = prepare_df_for_alignment_calculation(human_annotation_dataset_path, machine_annotation_dataset_path)\n",
    "    \n",
    "    alignment_score = calculate_alignment_score(h_df, m_df)\n",
    "    \n",
    "    alignment_score_df.loc[dataset_name, machine_annotation_folder_path] = alignment_score\n",
    "    \n",
    "    return alignment_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2163566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e71968",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_score_df = pd.DataFrame()\n",
    "alignment_score_df['datasets'] = dataset_names_list\n",
    "alignment_score_df.set_index('datasets', inplace=True)\n",
    "\n",
    "for dataset_name in dataset_names_list:\n",
    "    \n",
    "    ##STRICT CONSISTENCY\n",
    "    # no_context_strict_consistency_chatgpt\n",
    "    calculate_dataset_alignment_code(path_strict_consistency_human_annotation, \n",
    "                                     path_no_context_strict_consistency_chatgpt, \n",
    "                                     dataset_name, \n",
    "                                     alignment_score_df)\n",
    "    \n",
    "    # no_context_strict_consistency_googlebard\n",
    "    calculate_dataset_alignment_code(path_strict_consistency_human_annotation, \n",
    "                                     path_no_context_strict_consistency_googlebard, \n",
    "                                     dataset_name, \n",
    "                                     alignment_score_df)\n",
    "    \n",
    "    # context_strict_consistency_chatgpt\n",
    "    calculate_dataset_alignment_code(path_strict_consistency_human_annotation, \n",
    "                                     path_context_strict_consistency_chatgpt, \n",
    "                                     dataset_name, \n",
    "                                     alignment_score_df)\n",
    "    \n",
    "    ##SOFT CONSISTENCY\n",
    "    # no_context_soft_consistency_chatgpt\n",
    "    calculate_dataset_alignment_code(path_soft_consistency_human_annotation, \n",
    "                                     path_no_context_soft_consistency_chatgpt, \n",
    "                                     dataset_name, \n",
    "                                     alignment_score_df)\n",
    "    \n",
    "    # no_context_soft_consistency_googlebard\n",
    "    calculate_dataset_alignment_code(path_soft_consistency_human_annotation, \n",
    "                                     path_no_context_soft_consistency_googlebard, \n",
    "                                     dataset_name, \n",
    "                                     alignment_score_df)\n",
    "    \n",
    "    # context_soft_consistency_chatgpt\n",
    "    calculate_dataset_alignment_code(path_soft_consistency_human_annotation, \n",
    "                                     path_context_soft_consistency_chatgpt, \n",
    "                                     dataset_name, \n",
    "                                     alignment_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26940b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_score_df.to_csv('/Users/brain/Documents/GitHub/LLMs-topic-classification/results/alignment_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e1b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0fbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46b7df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
