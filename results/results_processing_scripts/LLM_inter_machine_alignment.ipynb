{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7db3b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.formula.api import ols\n",
    "from minineedle import needle, smith, core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9da3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strict consistency\n",
    "path_no_context_strict_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/ChatGPT/strict_consistency/'\n",
    "path_no_context_strict_consistency_googlebard = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleBard/strict_consistency/'\n",
    "path_no_context_strict_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleGemini/strict_consistency/'\n",
    "path_context_strict_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/ChatGPT/strict_consistency/'\n",
    "path_context_strict_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/GoogleGemini/strict_consistency/'\n",
    "\n",
    "#soft consistency\n",
    "path_no_context_soft_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/ChatGPT/soft_consistency/'\n",
    "path_no_context_soft_consistency_googlebard = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleBard/soft_consistency/'\n",
    "path_no_context_soft_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleGemini/soft_consistency/'\n",
    "path_context_soft_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/ChatGPT/soft_consistency/'\n",
    "path_context_soft_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/GoogleGemini/soft_consistency/'\n",
    "\n",
    "dataset_paths_list_strict = [path_no_context_strict_consistency_chatgpt,\n",
    "                             path_no_context_strict_consistency_googlebard,\n",
    "                             path_no_context_strict_consistency_googlegemini,\n",
    "                             path_context_strict_consistency_chatgpt,\n",
    "                             path_context_strict_consistency_googlegemini]\n",
    "                      \n",
    "dataset_paths_list_soft = [path_no_context_soft_consistency_chatgpt,\n",
    "                           path_no_context_soft_consistency_googlebard,\n",
    "                           path_no_context_soft_consistency_googlegemini,\n",
    "                           path_context_soft_consistency_chatgpt,\n",
    "                           path_context_soft_consistency_googlegemini]\n",
    "\n",
    "dataset_paths_list_context = [path_context_strict_consistency_chatgpt,\n",
    "                              path_context_strict_consistency_googlegemini,\n",
    "                              path_context_soft_consistency_chatgpt,\n",
    "                              path_context_soft_consistency_googlegemini]\n",
    "\n",
    "dataset_paths_list_no_context = [path_no_context_strict_consistency_chatgpt,\n",
    "                                 path_no_context_strict_consistency_googlebard,\n",
    "                                 path_no_context_strict_consistency_googlegemini,\n",
    "                                 path_no_context_soft_consistency_chatgpt,\n",
    "                                 path_no_context_soft_consistency_googlebard,\n",
    "                                 path_no_context_soft_consistency_googlegemini]\n",
    "\n",
    "#datasets names list\n",
    "dataset_names_list = ['Education_expenditure_and_indicators.csv',\n",
    "                      'Health_expectancy.csv',\n",
    "                      'Listed_monuments.csv', \n",
    "                      'Livestock.csv',\n",
    "                      'Milk_supply_and_dairy_production.csv',\n",
    "                      'Mobility.csv',\n",
    "                      'Plant_protection_products.csv',\n",
    "                      'Population_dynamics.csv',\n",
    "                      'Social_security.csv',\n",
    "                      'Trade_and_industry.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da0a664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_pairs = [('run1', 'run1'), ('run1', 'run2'), ('run1', 'run3'), ('run1', 'run4'), ('run1', 'run5'), \n",
    "             ('run1', 'run6'), ('run1', 'run7'), ('run1', 'run8'), ('run1', 'run9'), ('run1', 'run10'), \n",
    "             ('run2', 'run1'), ('run2', 'run2'), ('run2', 'run3'), ('run2', 'run4'), ('run2', 'run5'), \n",
    "             ('run2', 'run6'), ('run2', 'run7'), ('run2', 'run8'), ('run2', 'run9'), ('run2', 'run10'), \n",
    "             ('run3', 'run1'), ('run3', 'run2'), ('run3', 'run3'), ('run3', 'run4'), ('run3', 'run5'), \n",
    "             ('run3', 'run6'), ('run3', 'run7'), ('run3', 'run8'), ('run3', 'run9'), ('run3', 'run10'), \n",
    "             ('run4', 'run1'), ('run4', 'run2'), ('run4', 'run3'), ('run4', 'run4'), ('run4', 'run5'),\n",
    "             ('run4', 'run6'), ('run4', 'run7'), ('run4', 'run8'), ('run4', 'run9'), ('run4', 'run10'),\n",
    "             ('run5', 'run1'), ('run5', 'run2'), ('run5', 'run3'), ('run5', 'run4'), ('run5', 'run5'),\n",
    "             ('run5', 'run6'), ('run5', 'run7'), ('run5', 'run8'), ('run5', 'run9'), ('run5', 'run10'),\n",
    "             ('run6', 'run1'), ('run6', 'run2'), ('run6', 'run3'), ('run6', 'run4'), ('run6', 'run5'),\n",
    "             ('run6', 'run6'), ('run6', 'run7'), ('run6', 'run8'), ('run6', 'run9'), ('run6', 'run10'), \n",
    "             ('run7', 'run1'), ('run7', 'run2'), ('run7', 'run3'), ('run7', 'run4'), ('run7', 'run5'), \n",
    "             ('run7', 'run6'), ('run7', 'run7'), ('run7', 'run8'), ('run7', 'run9'), ('run7', 'run10'), \n",
    "             ('run8', 'run1'), ('run8', 'run2'), ('run8', 'run3'), ('run8', 'run4'), ('run8', 'run5'), \n",
    "             ('run8', 'run6'), ('run8', 'run7'), ('run8', 'run8'), ('run8', 'run9'), ('run8', 'run10'), \n",
    "             ('run9', 'run1'), ('run9', 'run2'), ('run9', 'run3'), ('run9', 'run4'), ('run9', 'run5'), \n",
    "             ('run9', 'run6'), ('run9', 'run7'), ('run9', 'run8'), ('run9', 'run9'), ('run9', 'run10'),\n",
    "             ('run10', 'run1'), ('run10', 'run2'), ('run10', 'run3'), ('run10', 'run4'), ('run10', 'run5'), \n",
    "             ('run10', 'run6'), ('run10', 'run7'), ('run10', 'run8'), ('run10', 'run9'), ('run10', 'run10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aed7fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_id_column(df):\n",
    "    \n",
    "    # Drop the column 'ID' if it exists\n",
    "    if 'ID' in df.columns:\n",
    "        df = df.drop(columns=['ID'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60e54957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_index_column(df):\n",
    "    \n",
    "    # Set run_index as index column\n",
    "    df.set_index('run_index', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9791fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_row_to_sequence(df, row_pair):\n",
    "    \n",
    "    # Extract row values to list\n",
    "    seq1 = df.loc[row_pair[0]].tolist()\n",
    "    seq2 = df.loc[row_pair[1]].tolist()\n",
    "    \n",
    "    return seq1, seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4fe01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_not_found_from_sequence(seq):\n",
    "    \n",
    "    seq = [x for x in seq if x != 'NOT_FOUND']\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8c53baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_alignment_score(seq1, seq2, n_cols1, n_cols2):\\n    \\n    alignment: needle.NeedlemanWunsch[str] = needle.NeedlemanWunsch(seq1, seq2)\\n    \\n    alignment.change_matrix(core.ScoreMatrix(match=1, miss=-0.5, gap=-2))\\n    \\n    if len(seq1) == 0 and len(seq2) == 0:\\n        pair_alignment_score = -2\\n        return pair_alignment_score\\n    \\n    else:\\n        alignment.align()\\n        \\n        if len(seq1) > len(seq2):\\n            longer_seq = seq1\\n        elif len(seq1) < len(seq2):\\n            longer_seq = seq2\\n        else:\\n            longer_seq = seq1  # or seq2, since they are the same length\\n        \\n        if n_cols1 > n_cols2:\\n            max_n_cols = n_cols1\\n        elif n_cols1 < n_cols2:\\n            max_n_cols = n_cols2\\n        else:\\n            max_n_cols = n_cols1\\n            \\n        if max_n_cols > len(longer_seq):\\n            additional_penalty = -2*(max_n_cols-len(longer_seq)) # additional penalty for when both pairs have missing values\\n            pair_alignment_score = (alignment.get_score()+(additional_penalty))/max_n_cols #dividing by the number of columns\\n            return pair_alignment_score\\n        else:\\n            pair_alignment_score = alignment.get_score()/max_n_cols #dividing by the number of columns\\n            return pair_alignment_score\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_alignment_score(seq1, seq2, n_cols1, n_cols2):\n",
    "    \n",
    "    alignment: needle.NeedlemanWunsch[str] = needle.NeedlemanWunsch(seq1, seq2)\n",
    "    \n",
    "    alignment.change_matrix(core.ScoreMatrix(match=1, miss=-0.5, gap=-2))\n",
    "    \n",
    "    if len(seq1) == 0 and len(seq2) == 0:\n",
    "        pair_alignment_score = -2\n",
    "        return pair_alignment_score\n",
    "    \n",
    "    else:\n",
    "        alignment.align()\n",
    "        \n",
    "        if len(seq1) > len(seq2):\n",
    "            longer_seq = seq1\n",
    "        elif len(seq1) < len(seq2):\n",
    "            longer_seq = seq2\n",
    "        else:\n",
    "            longer_seq = seq1  # or seq2, since they are the same length\n",
    "        \n",
    "        if n_cols1 > n_cols2:\n",
    "            max_n_cols = n_cols1\n",
    "        elif n_cols1 < n_cols2:\n",
    "            max_n_cols = n_cols2\n",
    "        else:\n",
    "            max_n_cols = n_cols1\n",
    "            \n",
    "        if max_n_cols > len(longer_seq):\n",
    "            additional_penalty = -2*(max_n_cols-len(longer_seq)) # additional penalty for when both pairs have missing values\n",
    "            pair_alignment_score = (alignment.get_score()+(additional_penalty))/max_n_cols #dividing by the number of columns\n",
    "            return pair_alignment_score\n",
    "        else:\n",
    "            pair_alignment_score = alignment.get_score()/max_n_cols #dividing by the number of columns\n",
    "            return pair_alignment_score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment_score(seq1, seq2, n_cols1, n_cols2):\n",
    "    \n",
    "    alignment: needle.NeedlemanWunsch[str] = needle.NeedlemanWunsch(seq1, seq2)\n",
    "    \n",
    "    alignment.change_matrix(core.ScoreMatrix(match=1, miss=-0.5, gap=-2))\n",
    "    \n",
    "    if len(seq1) == 0 and len(seq2) == 0:\n",
    "        pair_alignment_score = -2\n",
    "        return pair_alignment_score\n",
    "    \n",
    "    else:\n",
    "        alignment.align()\n",
    "        \n",
    "        if len(seq1) > len(seq2):\n",
    "            longer_seq = seq1\n",
    "        elif len(seq1) < len(seq2):\n",
    "            longer_seq = seq2\n",
    "        else:\n",
    "            longer_seq = seq1  # or seq2, since they are the same length\n",
    "        \n",
    "        if n_cols1 > n_cols2:\n",
    "            max_n_cols = n_cols1\n",
    "        elif n_cols1 < n_cols2:\n",
    "            max_n_cols = n_cols2\n",
    "        else:\n",
    "            max_n_cols = n_cols1\n",
    "            \n",
    "        if max_n_cols > len(longer_seq):\n",
    "            additional_penalty = -2*(max_n_cols-len(longer_seq)) # additional penalty for when both pairs have missing values\n",
    "            pair_alignment_score = (alignment.get_score()+(additional_penalty))/max_n_cols #dividing by the number of columns\n",
    "            return pair_alignment_score\n",
    "        else:\n",
    "            pair_alignment_score = alignment.get_score()/max_n_cols #dividing by the number of columns\n",
    "            return pair_alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48871269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alignment_datasets_pair(row_pairs, df1, df2):\n",
    "    \n",
    "    for row_pair in row_pairs:\n",
    "        \n",
    "        seq1 = df1.loc[row_pair[0]].tolist()\n",
    "        seq2 = df2.loc[row_pair[1]].tolist()\n",
    "        \n",
    "        seq1 = remove_not_found_from_sequence(seq1)\n",
    "        seq2 = remove_not_found_from_sequence(seq2)\n",
    "        \n",
    "        n_cols_df1 = df1.shape[1]\n",
    "        n_cols_df2 = df2.shape[1]\n",
    "        \n",
    "        dataset_alignment_score = get_alignment_score(seq1, seq2, n_cols_df1, n_cols_df2)\n",
    "        \n",
    "        return dataset_alignment_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "294d3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY STRICT CONSISTENCY + NO-CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf218c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_strict_no_context = pd.DataFrame(columns=['setting', 'system_pair', 'dataset', 'alignment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5169aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names_list:\n",
    "    df_no_context_strict_chatgpt = pd.read_csv(os.path.join(path_no_context_strict_consistency_chatgpt, dataset_name))\n",
    "    df_no_context_strict_googlebard = pd.read_csv(os.path.join(path_no_context_strict_consistency_googlebard, dataset_name))\n",
    "    df_no_context_strict_googlegemini = pd.read_csv(os.path.join(path_no_context_strict_consistency_googlegemini, dataset_name))\n",
    "    \n",
    "    df_no_context_strict_chatgpt = remove_id_column(df_no_context_strict_chatgpt)\n",
    "    df_no_context_strict_googlebard = remove_id_column(df_no_context_strict_googlebard)\n",
    "    df_no_context_strict_googlegemini = remove_id_column(df_no_context_strict_googlegemini)\n",
    "    \n",
    "    df_no_context_strict_chatgpt = set_index_column(df_no_context_strict_chatgpt)\n",
    "    df_no_context_strict_googlebard = set_index_column(df_no_context_strict_googlebard)\n",
    "    df_no_context_strict_googlegemini = set_index_column(df_no_context_strict_googlegemini)\n",
    "    \n",
    "    # chatgpt vs bard\n",
    "    \n",
    "    dataset_alignment_score_no_context_strict_gpt_bard = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_no_context_strict_chatgpt,\n",
    "                                                                                          df_no_context_strict_googlebard)\n",
    "    \n",
    "    results_df_strict_no_context.loc[len(results_df_strict_no_context)] = [\"no-context/strict\", \n",
    "                                                                           \"ChatGPTvsGoogleBard\" ,\n",
    "                                                                            dataset_name, \n",
    "                                                    dataset_alignment_score_no_context_strict_gpt_bard/len(row_pairs)]\n",
    "    \n",
    "    # chatgpt vs gemini\n",
    "    dataset_alignment_score_no_context_strict_gpt_gemini = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_no_context_strict_chatgpt,\n",
    "                                                                                          df_no_context_strict_googlegemini)\n",
    "    \n",
    "    results_df_strict_no_context.loc[len(results_df_strict_no_context)] = [\"no-context/strict\", \n",
    "                                                                           \"ChatGPTvsGoogleGemini\" ,\n",
    "                                                                           dataset_name, \n",
    "                                                     dataset_alignment_score_no_context_strict_gpt_gemini/len(row_pairs)]\n",
    "    \n",
    "    # bard vs gemini\n",
    "    dataset_alignment_score_no_context_strict_bard_gemini = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_no_context_strict_googlebard,\n",
    "                                                                                          df_no_context_strict_googlegemini)\n",
    "    \n",
    "    results_df_strict_no_context.loc[len(results_df_strict_no_context)] = [\"no-context/strict\", \n",
    "                                                                           \"GoogleBardvsGoogleGemini\" ,\n",
    "                                                                           dataset_name, \n",
    "                                                     dataset_alignment_score_no_context_strict_bard_gemini/len(row_pairs)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c3f719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "142f6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY SOFT CONSISTENCY + NO-CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2aa8081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_soft_no_context = pd.DataFrame(columns=['setting', 'system_pair', 'dataset', 'alignment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "524bb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names_list:\n",
    "    df_no_context_soft_chatgpt = pd.read_csv(os.path.join(path_no_context_soft_consistency_chatgpt, dataset_name))\n",
    "    df_no_context_soft_googlebard = pd.read_csv(os.path.join(path_no_context_soft_consistency_googlebard, dataset_name))\n",
    "    df_no_context_soft_googlegemini = pd.read_csv(os.path.join(path_no_context_soft_consistency_googlegemini, dataset_name))\n",
    "    \n",
    "    df_no_context_soft_chatgpt = remove_id_column(df_no_context_soft_chatgpt)\n",
    "    df_no_context_soft_googlebard = remove_id_column(df_no_context_soft_googlebard)\n",
    "    df_no_context_soft_googlegemini = remove_id_column(df_no_context_soft_googlegemini)\n",
    "    \n",
    "    df_no_context_soft_chatgpt = set_index_column(df_no_context_soft_chatgpt)\n",
    "    df_no_context_soft_googlebard = set_index_column(df_no_context_soft_googlebard)\n",
    "    df_no_context_soft_googlegemini = set_index_column(df_no_context_soft_googlegemini)\n",
    "    \n",
    "    # chatgpt vs bard\n",
    "    \n",
    "    dataset_alignment_score_no_context_soft_gpt_bard = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_no_context_soft_chatgpt,\n",
    "                                                                                          df_no_context_soft_googlebard)\n",
    "    \n",
    "    results_df_soft_no_context.loc[len(results_df_soft_no_context)] = [\"no-context/soft\", \n",
    "                                                                           \"ChatGPTvsGoogleBard\" ,\n",
    "                                                                            dataset_name, \n",
    "                                                    dataset_alignment_score_no_context_soft_gpt_bard/len(row_pairs)]\n",
    "    \n",
    "    # chatgpt vs gemini\n",
    "    dataset_alignment_score_no_context_soft_gpt_gemini = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_no_context_soft_chatgpt,\n",
    "                                                                                          df_no_context_soft_googlegemini)\n",
    "    \n",
    "    results_df_soft_no_context.loc[len(results_df_soft_no_context)] = [\"no-context/soft\", \n",
    "                                                                           \"ChatGPTvsGoogleGemini\" ,\n",
    "                                                                           dataset_name, \n",
    "                                                     dataset_alignment_score_no_context_soft_gpt_gemini/len(row_pairs)]\n",
    "    \n",
    "    # bard vs gemini\n",
    "    dataset_alignment_score_no_context_soft_bard_gemini = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_no_context_soft_googlebard,\n",
    "                                                                                          df_no_context_soft_googlegemini)\n",
    "    \n",
    "    results_df_soft_no_context.loc[len(results_df_soft_no_context)] = [\"no-context/soft\", \n",
    "                                                                           \"GoogleBardvsGoogleGemini\" ,\n",
    "                                                                           dataset_name, \n",
    "                                                     dataset_alignment_score_no_context_soft_bard_gemini/len(row_pairs)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd09be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a71d04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY STRICT CONSISTENCY + CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13d538e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_strict_context = pd.DataFrame(columns=['setting', 'system_pair', 'dataset', 'alignment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a043e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names_list:\n",
    "    df_context_strict_chatgpt = pd.read_csv(os.path.join(path_context_strict_consistency_chatgpt, dataset_name))\n",
    "    df_context_strict_googlegemini = pd.read_csv(os.path.join(path_context_strict_consistency_googlegemini, dataset_name))\n",
    "    \n",
    "    df_context_strict_chatgpt = remove_id_column(df_context_strict_chatgpt)\n",
    "    df_context_strict_googlegemini = remove_id_column(df_context_strict_googlegemini)\n",
    "    \n",
    "    df_context_strict_chatgpt = set_index_column(df_context_strict_chatgpt)\n",
    "    df_context_strict_googlegemini = set_index_column(df_context_strict_googlegemini)\n",
    "    \n",
    "    \n",
    "    # chatgpt vs gemini\n",
    "    dataset_alignment_score_context_strict_gpt_gemini = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_context_strict_chatgpt,\n",
    "                                                                                          df_context_strict_googlegemini)\n",
    "    \n",
    "    results_df_strict_context.loc[len(results_df_strict_context)] = [\"context/strict\", \n",
    "                                                                           \"ChatGPTvsGoogleGemini\" ,\n",
    "                                                                           dataset_name, \n",
    "                                                     dataset_alignment_score_context_strict_gpt_gemini/len(row_pairs)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58a82da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY SOFT CONSISTENCY + CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91a5ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_soft_context = pd.DataFrame(columns=['setting', 'system_pair', 'dataset', 'alignment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bcec3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names_list:\n",
    "    df_context_soft_chatgpt = pd.read_csv(os.path.join(path_context_soft_consistency_chatgpt, dataset_name))\n",
    "    df_context_soft_googlegemini = pd.read_csv(os.path.join(path_context_soft_consistency_googlegemini, dataset_name))\n",
    "    \n",
    "    df_context_soft_chatgpt = remove_id_column(df_context_soft_chatgpt)\n",
    "    df_context_soft_googlegemini = remove_id_column(df_context_soft_googlegemini)\n",
    "    \n",
    "    df_context_soft_chatgpt = set_index_column(df_context_soft_chatgpt)\n",
    "    df_context_soft_googlegemini = set_index_column(df_context_soft_googlegemini)\n",
    "    \n",
    "    \n",
    "    # chatgpt vs gemini\n",
    "    dataset_alignment_score_context_soft_gpt_gemini = calculate_alignment_datasets_pair(row_pairs,\n",
    "                                                                                          df_context_soft_chatgpt,\n",
    "                                                                                          df_context_soft_googlegemini)\n",
    "    \n",
    "    results_df_soft_context.loc[len(results_df_soft_context)] = [\"context/soft\", \n",
    "                                                                           \"ChatGPTvsGoogleGemini\" ,\n",
    "                                                                           dataset_name, \n",
    "                                                     dataset_alignment_score_context_soft_gpt_gemini/len(row_pairs)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07136e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbbea1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([results_df_strict_no_context, \n",
    "                         results_df_soft_no_context,\n",
    "                         results_df_strict_context,\n",
    "                         results_df_soft_context],\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('/Users/brain/Documents/GitHub/LLMs-topic-classification/results/statistics/NeedlemanWunsch_intra_llm_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ba21ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setting</th>\n",
       "      <th>system_pair</th>\n",
       "      <th>dataset</th>\n",
       "      <th>alignment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-context/strict</td>\n",
       "      <td>ChatGPTvsGoogleBard</td>\n",
       "      <td>Education_expenditure_and_indicators.csv</td>\n",
       "      <td>-0.004434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-context/strict</td>\n",
       "      <td>ChatGPTvsGoogleGemini</td>\n",
       "      <td>Education_expenditure_and_indicators.csv</td>\n",
       "      <td>-0.004434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-context/strict</td>\n",
       "      <td>GoogleBardvsGoogleGemini</td>\n",
       "      <td>Education_expenditure_and_indicators.csv</td>\n",
       "      <td>-0.003824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-context/strict</td>\n",
       "      <td>ChatGPTvsGoogleBard</td>\n",
       "      <td>Health_expectancy.csv</td>\n",
       "      <td>-0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-context/strict</td>\n",
       "      <td>ChatGPTvsGoogleGemini</td>\n",
       "      <td>Health_expectancy.csv</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>context/soft</td>\n",
       "      <td>ChatGPTvsGoogleGemini</td>\n",
       "      <td>Mobility.csv</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>context/soft</td>\n",
       "      <td>ChatGPTvsGoogleGemini</td>\n",
       "      <td>Plant_protection_products.csv</td>\n",
       "      <td>-0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>context/soft</td>\n",
       "      <td>ChatGPTvsGoogleGemini</td>\n",
       "      <td>Population_dynamics.csv</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>context/soft</td>\n",
       "      <td>ChatGPTvsGoogleGemini</td>\n",
       "      <td>Social_security.csv</td>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>context/soft</td>\n",
       "      <td>ChatGPTvsGoogleGemini</td>\n",
       "      <td>Trade_and_industry.csv</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              setting               system_pair  \\\n",
       "0   no-context/strict       ChatGPTvsGoogleBard   \n",
       "1   no-context/strict     ChatGPTvsGoogleGemini   \n",
       "2   no-context/strict  GoogleBardvsGoogleGemini   \n",
       "3   no-context/strict       ChatGPTvsGoogleBard   \n",
       "4   no-context/strict     ChatGPTvsGoogleGemini   \n",
       "..                ...                       ...   \n",
       "75       context/soft     ChatGPTvsGoogleGemini   \n",
       "76       context/soft     ChatGPTvsGoogleGemini   \n",
       "77       context/soft     ChatGPTvsGoogleGemini   \n",
       "78       context/soft     ChatGPTvsGoogleGemini   \n",
       "79       context/soft     ChatGPTvsGoogleGemini   \n",
       "\n",
       "                                     dataset  alignment_score  \n",
       "0   Education_expenditure_and_indicators.csv        -0.004434  \n",
       "1   Education_expenditure_and_indicators.csv        -0.004434  \n",
       "2   Education_expenditure_and_indicators.csv        -0.003824  \n",
       "3                      Health_expectancy.csv        -0.001786  \n",
       "4                      Health_expectancy.csv         0.002500  \n",
       "..                                       ...              ...  \n",
       "75                              Mobility.csv         0.000000  \n",
       "76             Plant_protection_products.csv        -0.005000  \n",
       "77                   Population_dynamics.csv         0.005000  \n",
       "78                       Social_security.csv         0.007632  \n",
       "79                    Trade_and_industry.csv         0.000294  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c400c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHATGPT vs BARD (no-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "730f68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_bard = combined_df[combined_df['system_pair'] == 'ChatGPTvsGoogleBard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "009f1af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setting</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.662812</td>\n",
       "      <td>8.791849e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>9.0</td>\n",
       "      <td>148.926006</td>\n",
       "      <td>1.050164e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sum_sq   df           F        PR(>F)\n",
       "setting   0.000001  1.0    3.662812  8.791849e-02\n",
       "dataset   0.000468  9.0  148.926006  1.050164e-08\n",
       "Residual  0.000003  9.0         NaN           NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('alignment_score ~ setting + dataset', data=df_gpt_bard).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "926f3783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Multiple Comparison of Means - Tukey HSD, FWER=0.05                                \n",
      "===================================================================================================================\n",
      "                 group1                                 group2                meandiff p-adj   lower  upper  reject\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Education_expenditure_and_indicators.csv                Health_expectancy.csv   0.0058 0.5779 -0.0039 0.0156  False\n",
      "Education_expenditure_and_indicators.csv                 Listed_monuments.csv  -0.0006    1.0 -0.0103 0.0091  False\n",
      "Education_expenditure_and_indicators.csv                        Livestock.csv   0.0007    1.0 -0.0091 0.0104  False\n",
      "Education_expenditure_and_indicators.csv Milk_supply_and_dairy_production.csv  -0.0009    1.0 -0.0107 0.0088  False\n",
      "Education_expenditure_and_indicators.csv                         Mobility.csv   0.0023 0.9978 -0.0074 0.0121  False\n",
      "Education_expenditure_and_indicators.csv        Plant_protection_products.csv  -0.0025 0.9964 -0.0122 0.0073  False\n",
      "Education_expenditure_and_indicators.csv              Population_dynamics.csv   0.0052 0.7094 -0.0045  0.015  False\n",
      "Education_expenditure_and_indicators.csv                  Social_security.csv   0.0022 0.9987 -0.0076 0.0119  False\n",
      "Education_expenditure_and_indicators.csv               Trade_and_industry.csv   0.0007    1.0  -0.009 0.0105  False\n",
      "                   Health_expectancy.csv                 Listed_monuments.csv  -0.0064 0.4461 -0.0162 0.0033  False\n",
      "                   Health_expectancy.csv                        Livestock.csv  -0.0052 0.7215 -0.0149 0.0046  False\n",
      "                   Health_expectancy.csv Milk_supply_and_dairy_production.csv  -0.0068 0.3763 -0.0165  0.003  False\n",
      "                   Health_expectancy.csv                         Mobility.csv  -0.0035 0.9611 -0.0132 0.0062  False\n",
      "                   Health_expectancy.csv        Plant_protection_products.csv  -0.0083 0.1471  -0.018 0.0014  False\n",
      "                   Health_expectancy.csv              Population_dynamics.csv  -0.0006    1.0 -0.0103 0.0091  False\n",
      "                   Health_expectancy.csv                  Social_security.csv  -0.0037 0.9497 -0.0134 0.0061  False\n",
      "                   Health_expectancy.csv               Trade_and_industry.csv  -0.0051 0.7368 -0.0148 0.0046  False\n",
      "                    Listed_monuments.csv                        Livestock.csv   0.0012    1.0 -0.0085  0.011  False\n",
      "                    Listed_monuments.csv Milk_supply_and_dairy_production.csv  -0.0003    1.0 -0.0101 0.0094  False\n",
      "                    Listed_monuments.csv                         Mobility.csv   0.0029 0.9884 -0.0068 0.0127  False\n",
      "                    Listed_monuments.csv        Plant_protection_products.csv  -0.0019 0.9996 -0.0116 0.0079  False\n",
      "                    Listed_monuments.csv              Population_dynamics.csv   0.0058 0.5773 -0.0039 0.0156  False\n",
      "                    Listed_monuments.csv                  Social_security.csv   0.0028  0.992  -0.007 0.0125  False\n",
      "                    Listed_monuments.csv               Trade_and_industry.csv   0.0013    1.0 -0.0084 0.0111  False\n",
      "                           Livestock.csv Milk_supply_and_dairy_production.csv  -0.0016 0.9999 -0.0113 0.0081  False\n",
      "                           Livestock.csv                         Mobility.csv   0.0017 0.9998 -0.0081 0.0114  False\n",
      "                           Livestock.csv        Plant_protection_products.csv  -0.0031 0.9815 -0.0129 0.0066  False\n",
      "                           Livestock.csv              Population_dynamics.csv   0.0046 0.8351 -0.0052 0.0143  False\n",
      "                           Livestock.csv                  Social_security.csv   0.0015 0.9999 -0.0082 0.0112  False\n",
      "                           Livestock.csv               Trade_and_industry.csv   0.0001    1.0 -0.0097 0.0098  False\n",
      "    Milk_supply_and_dairy_production.csv                         Mobility.csv   0.0033 0.9757 -0.0065  0.013  False\n",
      "    Milk_supply_and_dairy_production.csv        Plant_protection_products.csv  -0.0015 0.9999 -0.0113 0.0082  False\n",
      "    Milk_supply_and_dairy_production.csv              Population_dynamics.csv   0.0062 0.5012 -0.0036 0.0159  False\n",
      "    Milk_supply_and_dairy_production.csv                  Social_security.csv   0.0031 0.9823 -0.0066 0.0128  False\n",
      "    Milk_supply_and_dairy_production.csv               Trade_and_industry.csv   0.0017 0.9998 -0.0081 0.0114  False\n",
      "                            Mobility.csv        Plant_protection_products.csv  -0.0048 0.7982 -0.0145 0.0049  False\n",
      "                            Mobility.csv              Population_dynamics.csv   0.0029 0.9884 -0.0068 0.0127  False\n",
      "                            Mobility.csv                  Social_security.csv  -0.0002    1.0 -0.0099 0.0096  False\n",
      "                            Mobility.csv               Trade_and_industry.csv  -0.0016 0.9999 -0.0113 0.0081  False\n",
      "           Plant_protection_products.csv              Population_dynamics.csv   0.0077 0.2184  -0.002 0.0174  False\n",
      "           Plant_protection_products.csv                  Social_security.csv   0.0046 0.8257 -0.0051 0.0144  False\n",
      "           Plant_protection_products.csv               Trade_and_industry.csv   0.0032 0.9785 -0.0065 0.0129  False\n",
      "                 Population_dynamics.csv                  Social_security.csv  -0.0031 0.9836 -0.0128 0.0067  False\n",
      "                 Population_dynamics.csv               Trade_and_industry.csv  -0.0045 0.8472 -0.0142 0.0052  False\n",
      "                     Social_security.csv               Trade_and_industry.csv  -0.0014    1.0 -0.0112 0.0083  False\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tukey_results_system = pairwise_tukeyhsd(df_gpt_gemini['alignment_score'], df_gpt_gemini['dataset'])\n",
    "print(tukey_results_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f914d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHATGPT vs GEMINI (no-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bd2984ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_gemini_no_context = combined_df[combined_df['system_pair'] == 'GoogleBardvsGoogleGemini']\n",
    "df_gpt_gemini_no_context = df_gpt_gemini_no_context[df_gpt_gemini_no_context['setting'].isin(['no-context/strict', 'no-context/soft'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9eafcded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setting</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.054561</td>\n",
       "      <td>0.074892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.573870</td>\n",
       "      <td>0.254953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>0.000082</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sum_sq   df         F    PR(>F)\n",
       "setting   0.000037  1.0  4.054561  0.074892\n",
       "dataset   0.000129  9.0  1.573870  0.254953\n",
       "Residual  0.000082  9.0       NaN       NaN"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('alignment_score ~ setting + dataset', data=df_gpt_gemini_no_context).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b90916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bard vs GEMINI (no-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "051d544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bard_gemini_no_context = combined_df[combined_df['system_pair'] == 'GoogleBardvsGoogleGemini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "70b0bc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setting</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.475530</td>\n",
       "      <td>9.516270e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>9.0</td>\n",
       "      <td>201.096071</td>\n",
       "      <td>2.753239e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sum_sq   df           F        PR(>F)\n",
       "setting   0.000002  1.0    3.475530  9.516270e-02\n",
       "dataset   0.000800  9.0  201.096071  2.753239e-09\n",
       "Residual  0.000004  9.0         NaN           NaN"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('alignment_score ~ setting + dataset', data=df_bard_gemini_no_context).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "792a7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHATGPT vs GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "785353a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_gemini = combined_df[combined_df['system_pair'] == 'ChatGPTvsGoogleGemini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fa9dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ts/b1943r396fj_jxc57wkd2y040000gn/T/ipykernel_35701/2498313190.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_gpt_gemini[['context', 'softness']] = df_gpt_gemini['setting'].str.split('/', expand=True)\n",
      "/var/folders/ts/b1943r396fj_jxc57wkd2y040000gn/T/ipykernel_35701/2498313190.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_gpt_gemini[['context', 'softness']] = df_gpt_gemini['setting'].str.split('/', expand=True)\n"
     ]
    }
   ],
   "source": [
    "df_gpt_gemini[['context', 'softness']] = df_gpt_gemini['setting'].str.split('/', expand=True)\n",
    "df_gpt_gemini = df_gpt_gemini.drop(columns=['setting'])\n",
    "df_gpt_gemini = df_gpt_gemini.drop(columns=['system_pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bfd124b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>0.000252</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.003732</td>\n",
       "      <td>0.077177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.454914</td>\n",
       "      <td>0.237835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softness</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.472781</td>\n",
       "      <td>0.026676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>0.000392</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sum_sq    df         F    PR(>F)\n",
       "dataset   0.000252   9.0  2.003732  0.077177\n",
       "context   0.000020   1.0  1.454914  0.237835\n",
       "softness  0.000077   1.0  5.472781  0.026676\n",
       "Residual  0.000392  28.0       NaN       NaN"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('alignment_score ~ dataset + context + softness', data=df_gpt_gemini).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47de5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "  soft strict  -0.0028 0.0431 -0.0054 -0.0001   True\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tukey_results_system = pairwise_tukeyhsd(df_gpt_gemini['alignment_score'], df_gpt_gemini['softness'])\n",
    "print(tukey_results_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a4ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3c86c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BARD vs GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57fb32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bard_gemini = combined_df[combined_df['system_pair'] == 'GoogleBardvsGoogleGemini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b19dcb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setting</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.475530</td>\n",
       "      <td>9.516270e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>9.0</td>\n",
       "      <td>201.096071</td>\n",
       "      <td>2.753239e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sum_sq   df           F        PR(>F)\n",
       "setting   0.000002  1.0    3.475530  9.516270e-02\n",
       "dataset   0.000800  9.0  201.096071  2.753239e-09\n",
       "Residual  0.000004  9.0         NaN           NaN"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('alignment_score ~ setting + dataset', data=df_bard_gemini).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f715169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.753239e-09 < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438e29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
