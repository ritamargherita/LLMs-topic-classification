{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee034b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minineedle import needle, smith, core\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec1f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strict consistency\n",
    "path_no_context_strict_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/ChatGPT/strict_consistency/'\n",
    "path_no_context_strict_consistency_googlebard = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleBard/strict_consistency/'\n",
    "path_no_context_strict_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleGemini/strict_consistency/'\n",
    "path_context_strict_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/ChatGPT/strict_consistency/'\n",
    "path_context_strict_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/GoogleGemini/strict_consistency/'\n",
    "\n",
    "#soft consistency\n",
    "path_no_context_soft_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/ChatGPT/soft_consistency/'\n",
    "path_no_context_soft_consistency_googlebard = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleBard/soft_consistency/'\n",
    "path_no_context_soft_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/no-context/GoogleGemini/soft_consistency/'\n",
    "path_context_soft_consistency_chatgpt = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/ChatGPT/soft_consistency/'\n",
    "path_context_soft_consistency_googlegemini = '/Users/brain/Documents/GitHub/LLMs-topic-classification/results/mapped_csv/context/GoogleGemini/soft_consistency/'\n",
    "\n",
    "dataset_paths_list = [path_no_context_strict_consistency_chatgpt,\n",
    "                      path_no_context_strict_consistency_googlebard,\n",
    "                      path_no_context_strict_consistency_googlegemini,\n",
    "                      path_context_strict_consistency_chatgpt,\n",
    "                      path_context_strict_consistency_googlegemini,\n",
    "                      path_no_context_soft_consistency_chatgpt,\n",
    "                      path_no_context_soft_consistency_googlebard,\n",
    "                      path_no_context_soft_consistency_googlegemini,\n",
    "                      path_context_soft_consistency_chatgpt,\n",
    "                      path_context_soft_consistency_googlegemini]\n",
    "\n",
    "#datasets names list\n",
    "dataset_names_list = ['Education_expenditure_and_indicators.csv',\n",
    "                      'Health_expectancy.csv',\n",
    "                      'Listed_monuments.csv', \n",
    "                      'Livestock.csv',\n",
    "                      'Milk_supply_and_dairy_production.csv',\n",
    "                      'Mobility.csv',\n",
    "                      'Plant_protection_products.csv',\n",
    "                      'Population_dynamics.csv',\n",
    "                      'Social_security.csv',\n",
    "                      'Trade_and_industry.csv']\n",
    "\n",
    "row_pairs = [('run1', 'run2'), ('run1', 'run3'), ('run1', 'run4'), ('run1', 'run5'), ('run1', 'run6'),\n",
    "             ('run1', 'run7'), ('run1', 'run8'), ('run1', 'run9'), ('run1', 'run10'), ('run2', 'run3'),\n",
    "             ('run2', 'run4'), ('run2', 'run5'), ('run2', 'run6'), ('run2', 'run7'), ('run2', 'run8'),\n",
    "             ('run2', 'run9'), ('run2', 'run10'), ('run3', 'run4'), ('run3', 'run5'), ('run3', 'run6'),\n",
    "             ('run3', 'run7'), ('run3', 'run8'), ('run3', 'run9'), ('run3', 'run10'), ('run4', 'run5'),\n",
    "             ('run4', 'run6'), ('run4', 'run7'), ('run4', 'run8'), ('run4', 'run9'), ('run4', 'run10'),\n",
    "             ('run5', 'run6'), ('run5', 'run7'), ('run5', 'run8'), ('run5', 'run9'), ('run5', 'run10'),\n",
    "             ('run6', 'run7'), ('run6', 'run8'), ('run6', 'run9'), ('run6', 'run10'), ('run7', 'run8'),\n",
    "             ('run7', 'run9'), ('run7', 'run10'), ('run8', 'run9'), ('run8', 'run10'), ('run9', 'run10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51357e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_id_column(df):\n",
    "    \n",
    "    # Drop the column 'ID' if it exists\n",
    "    if 'ID' in df.columns:\n",
    "        df = df.drop(columns=['ID'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85894e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_index_column(df):\n",
    "    \n",
    "    # Set run_index as index column\n",
    "    df.set_index('run_index', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec4a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_row_to_sequence(df, row_pair):\n",
    "    \n",
    "    # Extract row values to list\n",
    "    seq1 = df.loc[row_pair[0]].tolist()\n",
    "    seq2 = df.loc[row_pair[1]].tolist()\n",
    "    \n",
    "    return seq1, seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a7e6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_not_found_from_sequence(seq):\n",
    "    \n",
    "    seq = [x for x in seq if x != 'NOT_FOUND']\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1a6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment_score(seq1, seq2, n_cols):\n",
    "    \n",
    "    alignment: needle.NeedlemanWunsch[str] = needle.NeedlemanWunsch(seq1, seq2)\n",
    "    \n",
    "    alignment.change_matrix(core.ScoreMatrix(match=1, miss=-0.5, gap=-2))\n",
    "    \n",
    "    if len(seq1) == 0 and len(seq2) == 0:\n",
    "        pair_alignment_score = -2\n",
    "        return pair_alignment_score\n",
    "    \n",
    "    else:\n",
    "        alignment.align()\n",
    "        \n",
    "        if len(seq1) > len(seq2):\n",
    "            longer_seq = seq1\n",
    "        elif len(seq1) < len(seq2):\n",
    "            longer_seq = seq2\n",
    "        else:\n",
    "            longer_seq = seq1  # or seq2, since they are the same length\n",
    "\n",
    "        if n_cols > len(longer_seq):\n",
    "            additional_penalty = -2*(n_cols-len(longer_seq)) # additional penalty for when both pairs have missing values\n",
    "            pair_alignment_score = (alignment.get_score()+(additional_penalty))/n_cols #dividing by the number of columns\n",
    "            return pair_alignment_score\n",
    "        else:\n",
    "            pair_alignment_score = alignment.get_score()/n_cols #dividing by the number of columns\n",
    "            return pair_alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052ba98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c736656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['setting', 'dataset', 'alignment_score'])\n",
    "\n",
    "for dataset_path in dataset_paths_list:\n",
    "    for dataset_name in dataset_names_list:\n",
    "        df = pd.read_csv(os.path.join(dataset_path, dataset_name))\n",
    "        df = remove_id_column(df)\n",
    "        df = set_index_column(df)\n",
    "        n_cols = df.shape[1]\n",
    "        \n",
    "        dataset_alignment_score = 0\n",
    "        \n",
    "        for row_pair in row_pairs:\n",
    "            seq1, seq2 = transform_row_to_sequence(df, row_pair)\n",
    "            seq1 = remove_not_found_from_sequence(seq1)\n",
    "            seq2 = remove_not_found_from_sequence(seq2)\n",
    "            pair_alignment_score = get_alignment_score(seq1, seq2, n_cols)\n",
    "            dataset_alignment_score += pair_alignment_score\n",
    "            \n",
    "        results_df.loc[len(results_df)] = [dataset_path, dataset_name, dataset_alignment_score/len(row_pairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c22d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('/Users/brain/Documents/GitHub/LLMs-topic-classification/results/statistics/NeedlemanWunsch_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ed5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6556a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
