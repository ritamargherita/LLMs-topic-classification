{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b66d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de6dc671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|█████████████████| 28.0/28.0 [00:00<00:00, 8.87kB/s]\n",
      "vocab.txt: 100%|█████████████████████████████| 232k/232k [00:00<00:00, 2.67MB/s]\n",
      "tokenizer.json: 100%|████████████████████████| 466k/466k [00:00<00:00, 10.2MB/s]\n",
      "config.json: 100%|██████████████████████████████| 570/570 [00:00<00:00, 256kB/s]\n",
      "model.safetensors: 100%|█████████████████████| 440M/440M [00:48<00:00, 8.99MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0974b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input text\n",
    "input_text = \"Education Sectors\"\n",
    "tokens = tokenizer(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e662a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BERT model outputs\n",
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72f8ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for [CLS] token (sentence embedding)\n",
    "sentence_embedding = outputs.last_hidden_state[:, 0, :].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba2dbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for individual tokens (word embeddings)\n",
    "token_embeddings = outputs.last_hidden_state.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527db66e",
   "metadata": {},
   "source": [
    "## Computing similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51deab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentence for similarity comparison\n",
    "example_sentence = \"Education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7481ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the example sentence\n",
    "example_encoding = tokenizer.batch_encode_plus(\n",
    "    [example_sentence],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True\n",
    ")\n",
    "example_input_ids = example_encoding['input_ids']\n",
    "example_attention_mask = example_encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823ee72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the example sentence\n",
    "with torch.no_grad():\n",
    "    example_outputs = model(example_input_ids, attention_mask=example_attention_mask)\n",
    "    example_sentence_embedding = example_outputs.last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d70b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the original sentence embedding and the example sentence embedding\n",
    "similarity_score = cosine_similarity(sentence_embedding, example_sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95725bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.6429632\n"
     ]
    }
   ],
   "source": [
    "# Print the similarity score\n",
    "print(\"Cosine Similarity Score:\", similarity_score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de0d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
